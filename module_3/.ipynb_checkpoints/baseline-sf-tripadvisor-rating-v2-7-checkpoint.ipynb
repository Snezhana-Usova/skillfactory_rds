{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n",
    "# Predict TripAdvisor Rating\n",
    "## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n",
    "**По ходу задачи:**\n",
    "* Прокачаем работу с pandas\n",
    "* Научимся работать с Kaggle Notebooks\n",
    "* Поймем как делать предобработку различных данных\n",
    "* Научимся работать с пропущенными данными (Nan)\n",
    "* Познакомимся с различными видами кодирования признаков\n",
    "* Немного попробуем [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков) (генерировать новые признаки)\n",
    "* И совсем немного затронем ML\n",
    "* И многое другое...   \n",
    "\n",
    "\n",
    "\n",
    "### И самое важное, все это вы сможете сделать самостоятельно!\n",
    "\n",
    "*Этот Ноутбук являетсся Примером/Шаблоном к этому соревнованию (Baseline) и не служит готовым решением!*   \n",
    "Вы можете использовать его как основу для построения своего решения.\n",
    "\n",
    "> что такое baseline решение, зачем оно нужно и почему предоставлять baseline к соревнованию стало важным стандартом на kaggle и других площадках.   \n",
    "**baseline** создается больше как шаблон, где можно посмотреть как происходит обращение с входящими данными и что нужно получить на выходе. При этом МЛ начинка может быть достаточно простой, просто для примера. Это помогает быстрее приступить к самому МЛ, а не тратить ценное время на чисто инженерные задачи. \n",
    "Также baseline являеться хорошей опорной точкой по метрике. Если твое решение хуже baseline - ты явно делаешь что-то не то и стоит попробовать другой путь) \n",
    "\n",
    "В контексте нашего соревнования baseline идет с небольшими примерами того, что можно делать с данными, и с инструкцией, что делать дальше, чтобы улучшить результат.  Вообще готовым решением это сложно назвать, так как используются всего 2 самых простых признака (а остальные исключаются)."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "# Загружаем специальный удобный инструмент для разделения датасета:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\n",
    "df_train = pd.read_csv(DATA_DIR+'/main_task.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\n",
    "sample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Подробнее по признакам:\n",
    "* City: Город \n",
    "* Cuisine Style: Кухня\n",
    "* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n",
    "* Price Range: Цены в ресторане в 3 категориях\n",
    "* Number of Reviews: Количество отзывов\n",
    "* Reviews: 2 последних отзыва и даты этих отзывов\n",
    "* URL_TA: страница ресторана на 'www.tripadvisor.com' \n",
    "* ID_TA: ID ресторана в TripAdvisor\n",
    "* Rating: Рейтинг ресторана"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "В датасете три количественных признака:\n",
    "* **Ranking**\n",
    "\n",
    "* **Rating**\n",
    "\n",
    "* **Number of Reviews**\n",
    "\n",
    "Семь номинативных признаков:\n",
    "* **Price Range**\n",
    "\n",
    "* **City**\n",
    "\n",
    "* **Cuisine Style**\n",
    "\n",
    "* **Reviews**\n",
    "\n",
    "* **Restaurant_id**\n",
    "\n",
    "* **ID_TA**\n",
    "\n",
    "* **URL_TA**\n",
    "\n",
    "Причем последние три признака можно отнести к \"техническим\", для построения модели их вряд ли нужно будет использовать.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим внимательнее на сложные признаки\n",
    "data['Cuisine Style'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Reviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['URL_TA'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Как видим, большинство признаков у нас требует очистки и предварительной обработки."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cleaning and Prepping Data\n",
    "Обычно данные содержат в себе кучу мусора, который необходимо почистить, для того чтобы привести их в приемлемый формат. Чистка данных — это необходимый этап решения почти любой реальной задачи.   \n",
    "![](https://analyticsindiamag.com/wp-content/uploads/2018/01/data-cleaning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 1. Обработка NAN \n",
    "У наличия пропусков могут быть разные причины, но пропуски нужно либо заполнить, либо исключить из набора полностью. Но с пропусками нужно быть внимательным, **даже отсутствие информации может быть важным признаком!**   \n",
    "По этому перед обработкой NAN лучше вынести информацию о наличии пропуска как отдельный признак "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим количество пропусков в каждом признаке и какой процент от всего датасета они занимают.\n",
    "nan_df = pd.DataFrame(data.isna().sum(), columns=['Количество'])\n",
    "\n",
    "nan_df['%'] = nan_df['Количество'].apply(lambda x: round((x/len(data))*100, 0))\n",
    "print(nan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Шесть из десяти колонок не имеют пропусков, в т.ч. целевая переменная - Rating.\n",
    "Колонки с пропущенными значениями:\n",
    "\n",
    "*Cuisine style*\n",
    "\n",
    "*Price range*\n",
    "\n",
    "*Number of Reviews*\n",
    "\n",
    "*Reviews*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вынесем наличие пропусков в указанных колонках (кроме Reviews) в отдельные признаки.\n",
    "data['Number_of_Reviews_isNAN'] = pd.isna(\n",
    "    data['Number of Reviews']).astype('uint8')\n",
    "data['Cuisine_style_isNAN'] = pd.isna(data['Cuisine Style']).astype('uint8')\n",
    "data['Price_range_isNAN'] = pd.isna(data['Price Range']).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 2. Обработка числовых признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Посмотрим распределение целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Rating'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 2.1. Number of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0, 0, 1, 0.8])\n",
    "axes.hist(data['Number of Reviews'], bins=100)\n",
    "axes.set_title('Распределение по количеству отзывов')\n",
    "axes.set_ylabel('Количество ресторанов')\n",
    "axes.set_xlabel('Количество отзывов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем пропуски в колонке средним количеством отзывов в зависимости от города\n",
    "data['Number of Reviews'] = data.groupby('City')['Number of Reviews'].transform(\n",
    "    lambda x: x.fillna(round(x.mean(), 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 2.2.  Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,7)\n",
    "df_train['Ranking'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['City'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['City'] == 'London'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на топ 10 городов\n",
    "for x in (df_train['City'].value_counts())[0:10].index:\n",
    "    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализуем признак Ranking в пределах каждого города\n",
    "means = data.groupby('City')['Ranking'].mean()\n",
    "std = data.groupby('City')['Ranking'].std()\n",
    "data['Ranking'] = (data.Ranking - data.City.map(means))/(data.City.map(std))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 3. Номинативные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.1. City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем дополнительный датасет для обработки колонки.\n",
    "\n",
    "df_cities = pd.read_csv('../input/world-cities-datasets/worldcities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим назвние 'Porto' к тому, что используется в датасете data - 'Oporto'\n",
    "df_cities['city_ascii'] = df_cities.city_ascii.apply(\n",
    "    lambda x: 'Oporto' if x == 'Porto' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.1.1. Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь из датасета df_cities, где ключ - город, значение - страна.\n",
    "df_cities_1 = df_cities.drop(\n",
    "    ['city', 'lat', 'lng', 'iso2', 'iso3', 'admin_name', 'capital', 'population', 'id'], axis=1)\n",
    "df_countries = df_cities_1[(df_cities_1['country'] != 'United States') & (\n",
    "    df_cities_1['country'] != 'Canada') & (df_cities_1['country'] != 'Venezuela')]\n",
    "df_countries.set_index(\"city_ascii\", drop=True, inplace=True)\n",
    "country_dict = df_countries.to_dict()\n",
    "country_dict_n = country_dict['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим новый признак - страна\n",
    "data['Country'] = data['City'].apply(lambda x: country_dict_n[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.1.2. Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь из датасета df_cities, где ключ - город, значение - размер населения\n",
    "df_population = df_cities[(df_cities['country'] != 'United States') & (\n",
    "    df_cities['country'] != 'Canada')]\n",
    "df_population = df_population.drop(\n",
    "    ['city', 'lat', 'lng', 'iso2', 'iso3', 'admin_name', 'capital', 'country', 'id'], axis=1)\n",
    "\n",
    "df_population.set_index(\"city_ascii\", drop=True, inplace=True)\n",
    "population_dict = df_population.to_dict()\n",
    "population_dict_n = population_dict['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополним датасет признаком - население города\n",
    "data['Population'] = data['City'].apply(lambda x: population_dict_n[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.1.3. Capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем множество из названий столиц из датасета df_cities\n",
    "capitals = set(df_cities[df_cities['capital'] == 'primary']['city_ascii'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для определения статуса города: столица или нет\n",
    "def capital_check(city):\n",
    "    if city in capitals:\n",
    "        return 'capital' \n",
    "    return 'non_capital'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополним датасет колонками, определяющими является город столицей или нет.\n",
    "data['Сity_status'] = data['City'].apply(capital_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.1.4. Tourists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим словарь с количеством туристов в каждом городе. Нужного датасета не нашлось, данные берем из отчета за 2018 год Euripean Cities Marketing, сайта statista.com и Википедии\n",
    "tourists_dict = {\n",
    "    'London': 71.16,\n",
    "    'Paris': 52.56,\n",
    "    'Madrid': 19.83,\n",
    "    'Barcelona': 19.29,\n",
    "    'Berlin': 32.87,\n",
    "    'Milan': 12.29,\n",
    "    'Rome': 28.55,\n",
    "    'Prague': 18.25,\n",
    "    'Lisbon': 10.76,\n",
    "    'Vienna': 17.41,\n",
    "    'Amsterdam': 16.94,\n",
    "    'Brussels': 3.91,\n",
    "    'Hamburg': 14.53,\n",
    "    'Munich': 17.12,\n",
    "    'Lyon': 3.5,\n",
    "    'Stockholm': 14.59,\n",
    "    'Warsaw': 3.0,\n",
    "    'Budapest' :12.5,\n",
    "    'Dublin': 11.2,\n",
    "    'Copenhagen': 5.9,\n",
    "    'Athens': 5.7,\n",
    "    'Edinburgh' :3.85,\n",
    "    'Zurich': 4.2,\n",
    "    'Oporto': 1.6,\n",
    "    'Geneva': 2.6,\n",
    "    'Krakow': 3.3,\n",
    "    'Oslo': 3.6,\n",
    "    'Helsinki': 1.2,\n",
    "    'Bratislava': 0.88,\n",
    "    'Luxembourg': 1.1,\n",
    "    'Ljubljana': 0.39\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим колонку с количеством иностранных туристов в каждом городе\n",
    "\n",
    "data['tourists_qnt'] = data['City'].apply(lambda x: tourists_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.2. Cuisine_style"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Определим самые популярные типы кухни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим строковые значения типов кухни к спискам\n",
    "data['Cuisine Style'] = data['Cuisine Style'].astype(str).apply(\n",
    "    lambda x: str(x).replace('[', '').replace(']', '').replace(\"'\", \"\").strip())\n",
    "\n",
    "data['Cuisine Style'] = data['Cuisine Style'].apply(lambda x:  None if x == 'nan' else [\n",
    "    info.strip() for info in str(x).split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем список из 10 самых популярных типов кухни\n",
    "cuisine_list = pd.DataFrame(data['Cuisine Style'].dropna(\n",
    ").tolist()).stack().value_counts().reset_index()\n",
    "top_cuisine = cuisine_list['index'][:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем отсутствующие значения в колонке на 'not_define'\n",
    "data['Cuisine Style'] = data['Cuisine Style'].apply(\n",
    "    lambda x: 'not_define' if x == None else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.2.1. Cuisine quantity[](http://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополняем датасет новым признаком 'cuisine_qnt' - количество типов кухни в каждом ресторане\n",
    "data['cuisine_qnt'] = data['Cuisine Style'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставляем только самые популярные кухни, остальные заменим на 'other'\n",
    "def check_cousine(raw):\n",
    "    line = []\n",
    "    top_list = ['Vegetarian Friendly', 'European', 'Mediterranean',\n",
    "                'Italian', 'Vegan Options', 'Gluten Free Options', 'Bar', 'French', 'Asian']\n",
    "    for item in raw:\n",
    "        if item.strip() == 'not_define':\n",
    "            line.append('not_define')\n",
    "        elif item.strip() in top_cuisine:\n",
    "            line.append(item.strip())\n",
    "        else:\n",
    "            line.append('other_cuisine')\n",
    "    return line\n",
    "\n",
    "\n",
    "data['Cuisine Style'] = data['Cuisine Style'].apply(check_cousine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополняем датасет колонками с типом кухни\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "data = data.join(pd.DataFrame(mlb.fit_transform(\n",
    "    data.pop('Cuisine Style')), index=data.index, columns=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.3. Price Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price Range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем пропуски в 'Price Range' наиболее часто встречающейся категорией\n",
    "data['Price Range'] = data['Price Range'].fillna('$$ - $$$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переводим значения из номинативного признака в ординарный с помощью словаря\n",
    "price_dict = {'$': 1, '$$ - $$$': 2, '$$$$': 3}\n",
    "data['Price Range'] = data['Price Range'].replace(to_replace=price_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.4. Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Reviews'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Пропущенных значений всего 2, но фактически пустых значений  гораздо больше, т.к. в 8112 строках указано '[[], []]' Заменим их на None и вынесем отсутствие отзывов в отдельный признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Reviews'] = data.Reviews.apply(lambda x: None if x == '[[], []]' else x)\n",
    "data['Review_isNAN'] = pd.isna(data['Reviews']).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем на два признака: содержащий отзывы и содержащий даты.\n",
    "data[['reviews_text', 'reviews_date']\n",
    "     ] = data['Reviews'].str.split(\"'],\", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.4.1. Reviews_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделим даты\n",
    "data['reviews_date'] = data.reviews_date.dropna().astype(str).apply(\n",
    "    lambda x: None if pd.isnull(x) else re.compile('\\d*/\\d*/\\d*').findall(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для формирования списка из дат в нужном формате\n",
    "def to_time(line):\n",
    "    line = [pd.to_datetime(item) for item in line]\n",
    "    return line\n",
    "\n",
    "\n",
    "data['reviews_date'] = data.reviews_date.dropna().apply(to_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для вычисления количество дней прошедших между первым и вторым отзывом\n",
    "def find_delta(line):\n",
    "    return (max(line) - min(line))\n",
    "\n",
    "\n",
    "data['delta_reviews_date'] = data['reviews_date'].dropna().apply(find_delta).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним пропуски 0\n",
    "data['delta_reviews_date'] = data['delta_reviews_date'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 3.4.2.  Reviews_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# приведем все буквы к нижнему регистру\n",
    "data['reviews_text'] = data.reviews_text.apply(\n",
    "    lambda x: x if pd.isnull(x) else x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделим из текста слова состоящие более чем из двух букв\n",
    "data['reviews_text_1'] = data.reviews_text.astype(str).apply(\n",
    "    lambda x: re.compile('[a-z][a-z]\\w+').findall(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим какие слова в отзывах встречаются чаще всего\n",
    "word_list = pd.DataFrame(data.reviews_text_1.dropna(\n",
    ").tolist()).stack().value_counts().reset_index()\n",
    "word_list[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим список из наиболее часто встречающихся прилагательных, описывающих впечатление.  Также добавим в список частицу \"not\"\n",
    "words_list = ['not', 'good', 'nice', 'great', 'very', 'best', 'excellent',\n",
    "              'delicious', 'friendly', 'lovely', 'amazing', 'tasty', 'fantastic', 'average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, которая оставляет в отзывах только наиболее часто встречающиеся слова\n",
    "def check_words(raw):\n",
    "    line = []\n",
    "    for item in raw:\n",
    "        if item in words_list:\n",
    "            line.append(item)\n",
    "        else:\n",
    "            continue\n",
    "    return line\n",
    "\n",
    "\n",
    "data['reviews_text_1'] = data['reviews_text_1'].apply(check_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем функцию для получения \"One-Hot-Encoded\" из списка.\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "data = data.join(pd.DataFrame(mlb.fit_transform(\n",
    "    data.pop('reviews_text_1')), index=data.index, columns=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для кодирования оставшихся категориальных признаков через подход One-Hot Encoding используем функцию get_dummies\n",
    "data = pd.get_dummies(data, columns=['City', 'Country', 'Сity_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Корреляция признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = data[data['sample'] == 1]\n",
    "plt.rcParams['figure.figsize'] = (15,10)\n",
    "sns.heatmap(data_corr.drop('sample', axis=1).corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Data Preprocessing¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем оставшиеся номинативные признаки\n",
    "object_columns = [s for s in data.columns if data[s].dtypes == 'object']\n",
    "data.drop(object_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализуем все данные кроме 'Rating','sample', 'Ranking'. Последний был нормализован ранее относительно городов.\n",
    "def StandardScaler_column(d_col):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data[[d_col]])\n",
    "    return scaler.transform(data[[d_col]])\n",
    "\n",
    "\n",
    "for i in list(data.columns):\n",
    "    if i not in ['Rating', 'sample', 'Ranking']:\n",
    "        data[i] = StandardScaler_column(i)\n",
    "        if len(data[data[i].isna()]) < len(data):\n",
    "            data[i] = data[i].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#### Запускаем и проверяем что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = data\n",
    "\n",
    "df_preproc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \n",
    "Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
    "# выделим 20% данных на валидацию (параметр test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем\n",
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model \n",
    "Сам ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель на тестовом наборе данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Submission\n",
    "Если все устраевает - готовим Submission на кагл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['Rating'] = predict_submission\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# What's next?\n",
    "Или что делать, чтоб улучшить результат:\n",
    "* Обработать оставшиеся признаки в понятный для машины формат\n",
    "* Посмотреть, что еще можно извлечь из признаков\n",
    "* Сгенерировать новые признаки\n",
    "* Подгрузить дополнительные данные, например: по населению или благосостоянию городов\n",
    "* Подобрать состав признаков\n",
    "\n",
    "В общем, процесс творческий и весьма увлекательный! Удачи в соревновании!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
